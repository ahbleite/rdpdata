package br.com.igti.data.rdp;

import java.util.ArrayList;
import java.util.Arrays;
import java.util.List;

import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.ml.Pipeline;
import org.apache.spark.ml.PipelineModel;
import org.apache.spark.ml.PipelineStage;
import org.apache.spark.ml.classification.NaiveBayes;
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator;
import org.apache.spark.ml.feature.HashingTF;
import org.apache.spark.ml.feature.IDF;
import org.apache.spark.ml.feature.Tokenizer;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.RowFactory;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.types.DataTypes;
import org.apache.spark.sql.types.StructField;
import org.apache.spark.sql.types.StructType;
import static org.apache.spark.sql.functions.*;
import org.apache.spark.api.java.JavaRDD;

public class NayveBayesSpamClassifier { 


	public static void main(String[] args) {

		SparkConf conf = new SparkConf()
				.setAppName("spamclassifier")
				.setMaster("local");		
		JavaSparkContext spContext = new JavaSparkContext(conf);
		SparkSession spSession = SparkSession
					  .builder()
					  .appName("spamclassifier")
					  .master("local")
					  .getOrCreate();

		//Cria um esquema para receber os dados
		StructType spamSchema = DataTypes
				.createStructType(new StructField[] {
					DataTypes.createStructField("label", 
								DataTypes.DoubleType, false),
					DataTypes.createStructField("message", 
								DataTypes.StringType, false)
					});
		
		Dataset<Row> spamDs = spSession.read()
					.csv("data/lv-atv2-smsspam.csv");
		
		// cria um novo RDD repartindo o arquivo orginal em duas partições
		JavaRDD<Row> rdd1 = spamDs.toJavaRDD().repartition(2);
		
		//transformação dos dados alterando as classes de saída para 0 e 1
		JavaRDD<Row> rdd2 = rdd1.map( new Function<Row, Row>() {
		    @Override
		    public Row call(Row iRow) throws Exception {			
			 double spam = (iRow.getString(0).equals("spam") ? 1.0 : 0.0); 			 Row retRow = RowFactory.create( spam, iRow.getString(1)	);			 return retRow;
		    }
		});
		
		// cria um novo dataFrame para os dados tansformados
		Dataset<Row> spamDsTransf = spSession
							.createDataFrame(rdd2, spamSchema);
		System.out.println("Dados transformados:");
		spamDsTransf.show(5);
		
		// define a divisão entre amostras de treinamento e de teste.
		Dataset<Row>[] splits = spamDsTransf.randomSplit(
							new double[]{0.7, 0.3});
		Dataset<Row> trainingData = splits[0];
		Dataset<Row> testData = splits[1];		
		/*-------------------------------------------------------------
		Extração de características
		-------------------------------------------------------------*/	
		// separa as palavras
		Tokenizer tokenizer = new Tokenizer()
								.setInputCol("message")
								.setOutputCol("words");
		// classe que extrai a frequencia com que cada palavra aparece
		HashingTF hashingTF = new HashingTF()
								.setInputCol("words")
								.setOutputCol("rawFeatures");
		// determina a frequenciad
		IDF idf = new IDF()
					.setInputCol("rawFeatures")
					.setOutputCol("features");
		// cria o classificador
		NaiveBayes nbClassifier = new NaiveBayes()
							.setLabelCol("label")
							.setFeaturesCol("features");
		// cria o pipeline com a sequencia de execução
		Pipeline pipeline = new Pipeline()
				  	.setStages(new PipelineStage[]
					  {tokenizer, hashingTF, idf, nbClassifier});
		/*---------------------------------------------------------------
		Treinamento
		----------------------------------------------------------------*/
		PipelineModel plModel = pipeline.fit(trainingData);
		/*--------------------------------------------------------------
		Classificação
		----------------------------------------------------------------*/
		Dataset<Row> predictions = plModel.transform(testData);
		predictions.show(5);		
		/*--------------------------------------------------------------
		Avaliação do Modelo
		----------------------------------------------------------------*/
		System.out.println("Matriz de Confusão:");
		predictions.groupBy(col("label"), col("prediction"))
									.count().show();
		
		//Calcula a métrica 
		MulticlassClassificationEvaluator evaluator =
						 new MulticlassClassificationEvaluator()
				  			.setLabelCol("label")
				  			.setPredictionCol("prediction")
				  			.setMetricName("accuracy");
		double accuracy = evaluator.evaluate(predictions);
		System.out.println("Acurácia=" + Math.round(accuracy * 100) + "%" );
				
		// mantem o programa ativo aguardando durante um tempo
		while (true) {
			try {
				Thread.sleep(1000);
			} catch (InterruptedException e) {				
				e.printStackTrace();
			}
		}
	}
}

